"""
Context analysis system for article relationships.

This module implements the contextual analysis that determines whether
articles are duplicates, updates, or independent content.
"""

import asyncio
import json
import yaml
from pathlib import Path
from typing import Dict, List, Optional

from src.llm.llm_router import LLMRouter
from src.models.schemas import ContextAnalysisResult, SummarizedArticle, RelatedArticleReference
from src.utils.embedding_manager import EmbeddingManager
from src.utils.logger import setup_logging

logger = setup_logging()


class ContextAnalyzer:
    """Analyzes contextual relationships between articles."""
    
    def __init__(
        self,
        embedding_manager: Optional[EmbeddingManager] = None,
        llm_router: Optional[LLMRouter] = None,
        prompts_dir: str = "src/prompts"
    ):
        """
        Initialize context analyzer.
        
        Args:
            embedding_manager: Embedding manager for similarity search
            llm_router: LLM router for context analysis
            prompts_dir: Directory containing prompt templates
        """
        self.embedding_manager = embedding_manager
        self.llm_router = llm_router or LLMRouter()
        self.prompts_dir = Path(prompts_dir)
        
        # Load prompts
        self.prompts = self._load_prompts()
    
    def _load_prompts(self) -> Dict:
        """Load context analysis prompts from YAML."""
        
        try:
            prompts_file = self.prompts_dir / "context_analysis.yaml"
            
            if not prompts_file.exists():
                logger.warning(f"Prompts file not found: {prompts_file}")
                return self._get_default_prompts()
            
            with open(prompts_file, 'r', encoding='utf-8') as f:
                prompts = yaml.safe_load(f)
            
            logger.debug("Loaded context analysis prompts")
            return prompts
            
        except Exception as e:
            logger.error("Failed to load prompts", error=str(e))
            return self._get_default_prompts()
    
    def _get_default_prompts(self) -> Dict:
        """Get default prompts if file loading fails."""
        
        return {
            "context_analysis_prompt": """
            ‰ªäÂõû„ÅÆ„Éã„É•„Éº„Çπ: {current_title}
            ÈÅéÂéª„ÅÆÈ°û‰ºº„Éã„É•„Éº„Çπ: {past_related_news}
            
            Âà§ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
            - SKIP: ÈáçË§á
            - UPDATE: Á∂öÂ†±
            - KEEP: Áã¨Á´ãË®ò‰∫ã
            
            JSONÂΩ¢Âºè„ÅßÂõûÁ≠î:
            {{"decision": "SKIP|UPDATE|KEEP", "reasoning": "ÁêÜÁî±", "confidence_score": 0.85}}
            """,
            "system_prompt": "„ÅÇ„Å™„Åü„ÅØAI„Éã„É•„Éº„ÇπË®ò‰∫ã„ÅÆÊñáËÑàÂàÜÊûêÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ"
        }
    
    async def analyze_context(
        self,
        current_article: SummarizedArticle,
        max_similar_articles: int = 5,
        similarity_threshold: float = 0.7
    ) -> ContextAnalysisResult:
        """
        Analyze context of current article against past articles.
        
        Args:
            current_article: Article to analyze
            max_similar_articles: Maximum similar articles to consider
            similarity_threshold: Minimum similarity for comparison
        
        Returns:
            ContextAnalysisResult with decision and reasoning
        """
        
        try:
            article_id = current_article.filtered_article.raw_article.id
            article_title = current_article.filtered_article.raw_article.title
            
            logger.info(
                "Starting context analysis",
                article_id=article_id,
                article_title=article_title[:50] + "..." if len(article_title) > 50 else article_title,
                similarity_threshold=similarity_threshold,
                max_similar_articles=max_similar_articles
            )
            
            # Find similar past articles
            similar_articles = []
            
            if self.embedding_manager:
                similar_articles = await self.embedding_manager.search_similar_articles(
                    query_article=current_article,
                    top_k=max_similar_articles,
                    similarity_threshold=similarity_threshold
                )
                
                logger.info(
                    "Similar articles search completed",
                    article_id=article_id,
                    found_count=len(similar_articles),
                    similarity_scores=[round(a["similarity_score"], 3) for a in similar_articles[:3]]
                )
            else:
                logger.warning("Embedding manager not available for context analysis", article_id=article_id)
            
            if not similar_articles:
                # No similar articles found - treat as independent
                return ContextAnalysisResult(
                    decision="KEEP",
                    reasoning="ÈÅéÂéª„Å´È°û‰ººË®ò‰∫ã„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„Åü„ÇÅ„ÄÅÁã¨Á´ã„Åó„ÅüÊñ∞„Åó„ÅÑË®ò‰∫ã„Å®„Åó„Å¶Âà§ÂÆö",
                    contextual_summary=None,
                    references=[],
                    similarity_score=0.0
                )
            
            # Analyze relationship using LLM
            analysis_result = await self._llm_context_analysis(
                current_article, similar_articles
            )
            
            logger.info(
                "Context analysis completed",
                article_id=current_article.filtered_article.raw_article.id,
                decision=analysis_result.decision,
                similar_articles_count=len(similar_articles),
                max_similarity=similar_articles[0]["similarity_score"] if similar_articles else 0
            )
            
            return analysis_result
            
        except Exception as e:
            logger.error(
                "Context analysis failed",
                article_id=current_article.filtered_article.raw_article.id,
                error=str(e)
            )
            
            # Fallback to KEEP decision
            return ContextAnalysisResult(
                decision="KEEP",
                reasoning=f"ÊñáËÑàÂàÜÊûê„Ç®„É©„Éº„ÅÆ„Åü„ÇÅÁã¨Á´ãË®ò‰∫ã„Å®„Åó„Å¶Âá¶ÁêÜ: {str(e)}",
                contextual_summary=None,
                references=[],
                similarity_score=0.0
            )
    
    async def _llm_context_analysis(
        self,
        current_article: SummarizedArticle,
        similar_articles: List[Dict]
    ) -> ContextAnalysisResult:
        """Use LLM to analyze article relationships."""
        
        try:
            raw_article = current_article.filtered_article.raw_article
            article_id = raw_article.id
            
            logger.info(
                "Starting LLM context analysis",
                article_id=article_id,
                similar_articles_count=len(similar_articles),
                max_similarity=similar_articles[0]["similarity_score"] if similar_articles else 0
            )
            
            # Prepare current article info
            current_info = {
                "title": raw_article.title,
                "content": raw_article.content[:1000],  # Limit for prompt
                "summary": " ".join(current_article.summary.summary_points),
                "date": raw_article.published_date.strftime("%Y-%m-%d")
            }
            
            # Prepare similar articles info
            past_news_text = ""
            reference_objects = []
            
            for i, article in enumerate(similar_articles):
                past_news_text += f"\n{i+1}. **{article['title']}**\n"
                past_news_text += f"   Êó•‰ªò: {article['published_date'][:10]}\n"
                past_news_text += f"   È°û‰ººÂ∫¶: {article['similarity_score']:.3f}\n"
                past_news_text += f"   Ë¶ÅÁ¥Ñ: {article['content_summary'][:200]}...\n"
                
                # Create RelatedArticleReference object with full metadata
                from datetime import datetime
                
                # Try multiple URL field names to ensure we get a valid URL
                url = (article.get('source_url') or 
                       article.get('url') or 
                       article.get('link') or 
                       article.get('source', {}).get('url') or
                       '')
                
                # Handle datetime parsing safely
                try:
                    if isinstance(article['published_date'], str):
                        pub_date = datetime.fromisoformat(article['published_date'].replace('Z', '+00:00'))
                    else:
                        pub_date = article['published_date']
                except (ValueError, KeyError):
                    pub_date = datetime.now()
                
                # Generate Japanese title if available
                japanese_title = article.get('japanese_title')
                if not japanese_title and await self._needs_translation(article['title']):
                    japanese_title = await self._generate_simple_japanese_title(article['title'])
                
                # Ensure URL is not empty
                if not url or url == '' or url == 'None':
                    # Try to construct specific URL from article metadata first
                    article_title_slug = self._generate_url_slug(article['title'])
                    source_id = article.get('source_id', 'unknown').lower()
                    
                    if 'techcrunch' in source_id:
                        # Try to create a more specific TechCrunch search URL
                        url = f"https://techcrunch.com/search/{article['article_id']}"
                    elif 'zenn' in source_id:
                        # Try to create more specific Zenn URLs based on content
                        if article_title_slug:
                            url = f"https://zenn.dev/search?q={article_title_slug[:50]}"
                        else:
                            url = f"https://zenn.dev/topics/ai"
                    elif 'github' in source_id:
                        url = f"https://github.com/search?q={article_title_slug[:50]}&type=repositories"
                    elif 'youtube' in source_id:
                        url = f"https://www.youtube.com/results?search_query={article_title_slug[:50]}"
                    elif 'reddit' in source_id:
                        url = f"https://www.reddit.com/search/?q={article_title_slug[:50]}"
                    else:
                        # More descriptive anchor fallback
                        url = f"#{article['article_id']}"
                
                ref_obj = RelatedArticleReference(
                    article_id=article['article_id'],
                    title=article['title'],
                    japanese_title=japanese_title,
                    url=url,
                    published_date=pub_date,
                    similarity_score=article['similarity_score']
                )
                reference_objects.append(ref_obj)
            
            # Create analysis prompt
            prompt = self.prompts["context_analysis_prompt"].format(
                current_title=current_info["title"],
                current_content=current_info["content"],
                current_summary=current_info["summary"],
                current_date=current_info["date"],
                past_related_news=past_news_text
            )
            
            logger.debug(
                "Context analysis prompt prepared",
                article_id=article_id,
                prompt_length=len(prompt),
                similar_articles_in_prompt=len(similar_articles)
            )
            
            # Use LLM router for analysis
            system_prompt = self.prompts.get("system_prompt", "")
            
            # Create a temporary summary output structure for LLM router
            # We'll parse the JSON response manually
            try:
                response = await self._call_llm_for_context_analysis(
                    system_prompt, prompt
                )
                
                logger.info(
                    "LLM context analysis response received",
                    article_id=article_id,
                    response_length=len(response) if response else 0
                )
                
                # Parse LLM response
                analysis_data = self._parse_llm_response(response)
                
                # CRITICAL: Validate SKIP decisions to prevent over-filtering
                # PRD F-5 requires 10 articles, so SKIP must be extremely conservative
                max_similarity = similar_articles[0]["similarity_score"] if similar_articles else 0.0
                decision = analysis_data.get("decision", "KEEP")
                
                # Override inappropriate SKIP decisions
                if decision == "SKIP" and max_similarity < 0.998:  # 99.8% threshold per prompt
                    # If LLM says SKIP but similarity < 99.8%, override to UPDATE or KEEP
                    if max_similarity > 0.75:
                        decision = "UPDATE"
                        analysis_data["reasoning"] = f"LLM„ÅÆSKIPÂà§ÂÆö„Çí‰øÆÊ≠£ÔºöÈ°û‰ººÂ∫¶{max_similarity:.3f}„Åß„ÅØÁ∂öÂ†±„Å®„Åó„Å¶Âá¶ÁêÜ„ÅåÈÅ©Âàá"
                        logger.info(
                            "Overrode inappropriate SKIP decision to UPDATE",
                            article_id=article_id,
                            similarity=max_similarity,
                            original_reasoning=analysis_data.get("reasoning", "")
                        )
                    else:
                        decision = "KEEP"
                        analysis_data["reasoning"] = f"LLM„ÅÆSKIPÂà§ÂÆö„Çí‰øÆÊ≠£ÔºöÈ°û‰ººÂ∫¶{max_similarity:.3f}„Åß„ÅØÁã¨Á´ãË®ò‰∫ã„Å®„Åó„Å¶Âá¶ÁêÜ„ÅåÈÅ©Âàá"
                        logger.info(
                            "Overrode inappropriate SKIP decision to KEEP",
                            article_id=article_id,
                            similarity=max_similarity,
                            original_reasoning=analysis_data.get("reasoning", "")
                        )
                
                # Create result with validated decision
                result = ContextAnalysisResult(
                    decision=decision,
                    reasoning=analysis_data.get("reasoning", "LLMÂàÜÊûêÂÆå‰∫Ü"),
                    contextual_summary=analysis_data.get("contextual_summary"),
                    references=reference_objects[:3],  # Limit references
                    similarity_score=max_similarity
                )
                
                logger.info(
                    "LLM context analysis completed",
                    article_id=article_id,
                    final_decision=result.decision,
                    reasoning_length=len(result.reasoning) if result.reasoning else 0,
                    has_contextual_summary=bool(result.contextual_summary),
                    references_count=len(result.references)
                )
                
                return result
                
            except Exception as llm_error:
                logger.error("LLM context analysis failed", error=str(llm_error))
                
                # F-16 UPDATE detection reconstruction - improved thresholds for reliable üÜô emoji assignment
                max_similarity = similar_articles[0]["similarity_score"] if similar_articles else 0.0
                
                # CRITICAL: Even stricter thresholds to prevent üÜô emoji overuse
                if max_similarity > 0.998:  # 99.8%+ similarity = SKIP (virtually identical)
                    decision = "SKIP"
                    reasoning = f"Ê•µ„ÇÅ„Å¶È´ò„ÅÑÈ°û‰ººÂ∫¶Ôºà{max_similarity:.3f}Ôºâ„Å´„Çà„ÇäÈáçË§á„Å®Âà§ÂÆö"
                elif max_similarity > 0.92:  # 92%+ similarity = UPDATE (ultra strict threshold)
                    decision = "UPDATE"
                    reasoning = f"Ê•µ„ÇÅ„Å¶È´ò„ÅÑÈ°û‰ººÂ∫¶Ôºà{max_similarity:.3f}Ôºâ„Å´„Çà„ÇäÊòéÁ¢∫„Å™Á∂öÂ†±„Å®Âà§ÂÆö - üÜôÁµµÊñáÂ≠ó‰ªò‰∏é"
                else:
                    decision = "KEEP"
                    reasoning = f"È°û‰ººÂ∫¶Ôºà{max_similarity:.3f}Ôºâ„Å´„Çà„ÇäÁã¨Á´ãË®ò‰∫ã„Å®Âà§ÂÆö"
                
                return ContextAnalysisResult(
                    decision=decision,
                    reasoning=reasoning,
                    contextual_summary=None,
                    references=reference_objects[:3],
                    similarity_score=max_similarity
                )
                
        except Exception as e:
            logger.error("LLM context analysis error", error=str(e))
            
            return ContextAnalysisResult(
                decision="KEEP",
                reasoning="ÂàÜÊûê„Ç®„É©„Éº„ÅÆ„Åü„ÇÅÁã¨Á´ãË®ò‰∫ã„Å®„Åó„Å¶Âá¶ÁêÜ",
                contextual_summary=None,
                references=[],
                similarity_score=0.0
            )
    
    async def _call_llm_for_context_analysis(
        self,
        system_prompt: str,
        user_prompt: str
    ) -> str:
        """Call LLM for context analysis."""
        
        # Use a simpler approach for context analysis
        # since we need JSON response rather than structured summary
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # Try each model in fallback order (primary + fallback models)
        all_models = self.llm_router.primary_models + self.llm_router.fallback_models
        for model_name in all_models:
            try:
                client = self.llm_router._get_client(model_name)
                
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
                
                response = await client.ainvoke(messages)
                return response.content
                
            except Exception as e:
                logger.warning(f"Model {model_name} failed for context analysis", error=str(e))
                continue
        
        raise Exception("All LLM models failed for context analysis")
    
    def _parse_llm_response(self, response: str) -> Dict:
        """Parse LLM JSON response."""
        
        try:
            # Try to extract JSON from response
            response = response.strip()
            
            # Find JSON in response (in case there's extra text)
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = response[json_start:json_end]
                data = json.loads(json_str)
                
                # Validate required fields
                if "decision" not in data:
                    data["decision"] = "KEEP"
                if "reasoning" not in data:
                    data["reasoning"] = "ÂàÜÊûêÂÆå‰∫Ü"
                if "confidence_score" not in data:
                    data["confidence_score"] = 0.5
                
                return data
            else:
                logger.warning("No JSON found in LLM response")
                return {"decision": "KEEP", "reasoning": "JSONËß£ÊûêÂ§±Êïó"}
                
        except json.JSONDecodeError as e:
            logger.error("Failed to parse LLM JSON response", error=str(e))
            return {"decision": "KEEP", "reasoning": "JSONËß£Êûê„Ç®„É©„Éº"}
        except Exception as e:
            logger.error("Unexpected error parsing LLM response", error=str(e))
            return {"decision": "KEEP", "reasoning": "Ëß£Êûê„Ç®„É©„Éº"}
    
    async def _needs_translation(self, title: str) -> bool:
        """Check if title needs Japanese translation."""
        import re
        
        # Simple heuristic: if title contains mostly non-Japanese characters
        japanese_chars = re.findall(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', title)
        total_chars = len(re.findall(r'[a-zA-Z0-9\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', title))
        
        if total_chars == 0:
            return True
            
        japanese_ratio = len(japanese_chars) / total_chars
        return japanese_ratio < 0.5  # Less than 50% Japanese characters
    
    async def _generate_simple_japanese_title(self, title: str) -> Optional[str]:
        """Generate simple Japanese title translation."""
        try:
            if not self.llm_router:
                return None
                
            prompt = f"""‰ª•‰∏ã„ÅÆËã±Ë™ûË®ò‰∫ã„Çø„Ç§„Éà„É´„ÇíÊó•Êú¨Ë™û„Å´ÁøªË®≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

„Çø„Ç§„Éà„É´: {title}

Ë¶ÅÊ±Ç:
- Ëá™ÁÑ∂„ÅßË™≠„Åø„ÇÑ„Åô„ÅÑÊó•Êú¨Ë™û
- 50ÊñáÂ≠ó‰ª•ÂÜÖ
- Â∞ÇÈñÄÁî®Ë™û„ÇíÈÅ©Âàá„Å´ÁøªË®≥

ÁøªË®≥:"""

            translation = await self.llm_router.generate_simple_text(
                prompt=prompt,
                max_tokens=100,
                temperature=0.2
            )
            
            if translation:
                # Clean response
                translation = translation.strip()
                # Remove common prefixes
                import re
                translation = re.sub(r'^(ÁøªË®≥[Ôºö:]?\s*|Êó•Êú¨Ë™û[Ôºö:]?\s*)', '', translation)
                translation = translation.strip('"\'„Äå„Äç')
                
                if len(translation) > 3 and len(translation) <= 60:
                    return translation
                    
        except Exception as e:
            logger.warning(f"Failed to generate Japanese title translation: {e}")
        
        return None
    
    def _generate_url_slug(self, title: str) -> str:
        """Generate URL-friendly slug from article title."""
        import re
        import urllib.parse
        
        if not title:
            return ""
        
        # Remove common prefixes and suffixes
        title = re.sub(r'^(„Äê[^„Äë]*„Äë|\\[.*?\\]|\d+[\.\)]\s*)', '', title)
        title = re.sub(r'(üÜô|[\u2600-\u26FF\u2700-\u27BF])', '', title)  # Remove emojis
        
        # Extract key terms (company names, tech terms, etc.)
        # Look for capitalized words, quoted terms, and key phrases
        key_terms = []
        
        # Extract quoted terms
        quoted_terms = re.findall(r'[„Äå„Äé"\'](.*?)[„Äç„Äè"\']', title)
        key_terms.extend(quoted_terms)
        
        # Extract English tech terms and company names
        english_terms = re.findall(r'\\b[A-Z][a-zA-Z]*(?:[A-Z][a-zA-Z]*)*\\b', title)
        key_terms.extend(english_terms)
        
        # Extract Japanese tech terms
        tech_terms = re.findall(r'(AI|LLM|API|CLI|GPU|CPU|SDK|ÈñãÁô∫|ÊäÄË°ì|„Ç∑„Çπ„ÉÜ„É†|„ÉÑ„Éº„É´|„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†)', title)
        key_terms.extend(tech_terms)
        
        # If we have key terms, use them
        if key_terms:
            # Take the most relevant terms (first 3)
            selected_terms = key_terms[:3]
            slug = ' '.join(selected_terms)
        else:
            # Fallback to first few words
            words = title.split()[:4]
            slug = ' '.join(words)
        
        # URL encode for search queries
        slug = urllib.parse.quote_plus(slug)
        return slug


async def analyze_article_context(
    article: SummarizedArticle,
    embedding_manager: Optional[EmbeddingManager] = None,
    llm_router: Optional[LLMRouter] = None
) -> ContextAnalysisResult:
    """
    Convenience function to analyze article context.
    
    Args:
        article: Article to analyze
        embedding_manager: Optional embedding manager
        llm_router: Optional LLM router
    
    Returns:
        ContextAnalysisResult
    """
    
    analyzer = ContextAnalyzer(embedding_manager, llm_router)
    return await analyzer.analyze_context(article)