# ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆè¦æ±‚ä»•æ§˜æ›¸ (PRD)

## 0. ãƒ¡ã‚¿æƒ…å ±
- **ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆå**: AI News v2 (Codename: "Hokusai")
- **ä½œæˆæ—¥**: 2025-06-21
- **ä½œæˆè€…**: Lawrence ï¼† AI Assistant
- **é–¢é€£ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: 10_personal/projects/podcast2newsletter/
- **å‚ç…§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: 6_templates/pm/prd_template.md

---

## 1. èƒŒæ™¯ãƒ»èª²é¡Œ

* RSS + YouTube ã®æœ€æ–° AI ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è‡ªå‹•åé›†
* LLM è¦ç´„ï¼‹é‡è¤‡é™¤å»ã§æ—¥æœ¬èª 3-4é …ç›®ã®ç®‡æ¡æ›¸ãã‚µãƒãƒªãƒ¼ç”Ÿæˆ
* Markdown å½¢å¼ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’å‡ºåŠ›
* Quaily CLI ã‚’ç”¨ã„ã¦ Quaily ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¸ API å…¥ç¨¿ (ç„¡æ–™æ )

ã‚’æ—¥æ¬¡ã§å®‰å®šé‹ç”¨ã§ãã‚‹è»½é‡ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

---

## 2. ç›®æ¨™ (SMART)
| # | æŒ‡æ¨™ | ç›®æ¨™å€¤ | è¨ˆæ¸¬æ–¹æ³• |
|---|------|-------|-----------|
| 1 | ç”ŸæˆæˆåŠŸç‡ | 95% ä»¥ä¸Š | GitHub Actions æˆåŠŸç‡ |
| 2 | ã‚µãƒãƒªãƒ¼æŒ‡ç¤ºèªæ··å…¥ç‡ | 0% | pytest æ­£è¦è¡¨ç¾æ¤œæŸ» |
| 3 | é‡è¤‡ãƒ‹ãƒ¥ãƒ¼ã‚¹æ··å…¥ç‡ | <5%/é€± | Supabase duplicate
events |
| 4 | å®Ÿè¡Œæ™‚é–“ | < 5 åˆ†/æ—¥ | GHA ã‚¸ãƒ§ãƒ–æ™‚é–“ |
| 5 | LLM API ã‚³ã‚¹ãƒˆ | < $1/æ—¥ | OpenAI Usage API |

---

## 3. ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ / ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒˆãƒ¼ãƒªãƒ¼
* **èª­è€… (AI/ML æ¥­ç•Œé–¢å¿ƒå±¤)** ã¨ã—ã¦ã€æœ€æ–° AI å‹•å‘ã‚’ 3 åˆ†ã§æŠŠæ¡ã—ãŸã„ã€‚
* **ç·¨é›†è€… (Lawrence)** ã¨ã—ã¦ã€æ–‡ç« ã‚’æ‰‹ä¿®æ­£ã™ã‚‹ä½™è£•ãŒç„¡ã„æ—¥ã§ã‚‚è³ªã®é«˜ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ãŒè‡ªå‹•ã§ä¸‹æ›¸ãã«å…¥ã£ã¦ã„ã¦æ¬²ã—ã„ã€‚
* **SNS æ‹¡æ•£æ‹…å½“** ã¨ã—ã¦ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼å…¬é–‹å¾Œã« X ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ç”Ÿæˆã—ãŸã„ (M2 ä»¥é™)ã€‚

---

## 4. ã‚¹ã‚³ãƒ¼ãƒ— (MVP)
### Inâ€Scope
1. **ã‚½ãƒ¼ã‚¹å–å¾—**  
   * æ—¢å­˜ RSS ä¸€è¦§ (content_sources ãƒ†ãƒ¼ãƒ–ãƒ«) ã¨ YouTube Channel ID ã‹ã‚‰æœ€æ–° 24h åˆ†ã‚’å–å¾—
2. **ãƒ•ã‚£ãƒ«ã‚¿ & ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°**  
   * AI é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç°¡æ˜“åˆ¤å®š (ã‚¿ã‚¤ãƒˆãƒ« + Description)
3. **LLM è¦ç´„ (Gemini 2.5 Pro â‡’ Claude 3.7 Sonnet â‡’ GPT-4o-mini)**  
   * 3é …ç›®ã®ç®‡æ¡æ›¸ã / å„é …ç›®200å­—ç¨‹åº¦ / æŒ‡ç¤ºèªç¦æ­¢
4. **é‡è¤‡é™¤å»**  
   * éå» 7 æ—¥é–“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ Jaccard+SequenceMatcher ã§æ¯”è¼ƒ
5. **ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° & è£œå¼·å¼•ç”¨**  
   * å½“æ—¥åˆ†ã®è¨˜äº‹ã‚’ Embedding + FAISS ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ä»£è¡¨è¨˜äº‹ã‚’é¸æŠã€‚æœ€å¤§ 3 ä»¶ã®å¼•ç”¨ã‚½ãƒ¼ã‚¹ã‚’æŠ½å‡ºã— Markdown å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã«å·®ã—è¾¼ã‚€
6. **éå»è¨˜äº‹æ–‡è„ˆåæ˜ ã‚·ã‚¹ãƒ†ãƒ **
   * Embeddingé¡ä¼¼æ¤œç´¢ã«ã‚ˆã‚‹éå»è¨˜äº‹ã¨ã®é–¢ä¿‚æ€§åˆ¤å®šã¨UPDATEå‡¦ç†
7. **Markdown ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ç”Ÿæˆ (Jinja2)**
8. **ãƒ­ãƒ¼ã‚«ãƒ« drafts ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®å‡ºåŠ›**
9. **Supabase ã¸ã®ãƒ­ã‚°è¨˜éŒ²** (processed_content / processing_logs / contextual_articles)
10. **GitHub Actions å®šæœŸå®Ÿè¡Œ (09:00 JST æ—¥æ¬¡)**

### Out-of-Scope (å°†æ¥æ‹¡å¼µ)
* Slacké€šçŸ¥æ©Ÿèƒ½ (Phase 4ã§å®Ÿè£…)
* Quaily CLI è‡ªå‹•å…¥ç¨¿ (Phase 4ã§å®Ÿè£…)
* Supabase pgvector ã¸ã®ç§»è¡Œ (Phase 5ã§æ¤œè¨ã€MVP ã¯ãƒ­ãƒ¼ã‚«ãƒ« FAISS)
* OGP ç”»åƒè‡ªå‹•ç”Ÿæˆ (Phase 5)
* Quaily æœ‰æ–™ Premium API ç­‰ã®æ‹¡å¼µ (Phase 5)
* X / Threads æ‹¡æ•£ãƒ•ãƒ­ãƒ¼ (Phase 5)

---

## 5. Functional Requirements
| ID | è¦ä»¶ |
|----|------|
| F-1 | RSS & YouTube ã‹ã‚‰æœ€å¤§ 30 ä»¶å–å¾—ã— `source_type` åˆ¥ã«æ­£è¦åŒ– |
| F-2 | ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜ã« AI ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œãªã„è¨˜äº‹ã¯é™¤å¤– |
| F-3 | Gemini 2.5 Pro ã‚’ç¬¬ä¸€å€™è£œã¨ã—ã€å¤±æ•—æ™‚ Claude 3.7 Sonnetã€æœ€çµ‚ fallback ã« GPT-4o-mini ã‚’ç”¨ã„ã¦æ—¥æœ¬èª 3-4é …ç›®ã®ç®‡æ¡æ›¸ãã‚µãƒãƒªãƒ¼ç”Ÿæˆã€‚NG ãƒ¯ãƒ¼ãƒ‰ã¯æ­£è¦è¡¨ç¾ã§é™¤å» |
| F-4 | éå» 7 æ—¥ãƒ‡ãƒ¼ã‚¿ã¨ Jaccard >0.7 ã¾ãŸã¯ SequenceRatio >0.85 ã¯é‡è¤‡ã¨åˆ¤å®šã— SKIP |
| F-5 | ä¸Šä½ 10 ä»¶ã¾ã§ã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼æœ¬æ–‡ã«æ•´å½¢ã— Markdown å‡ºåŠ› |
| F-6 | Supabase `processed_content` ã¸ upsertã€`processing_logs` ã¸å‡¦ç†ãƒ­ã‚°ã‚’æ®‹ã™ |
| F-7 | ç”Ÿæˆã•ã‚ŒãŸMarkdownãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ `drafts/YYYY-MM-DD_newsletter.md` ã¨ã—ã¦ä¿å­˜ã—ã€æ‰‹å‹•ç¢ºèªå¯èƒ½ãªçŠ¶æ…‹ã§å‡ºåŠ› |
| F-8 | GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ `python main.py --max-items 30 --edition daily` ã‚’æ—¥æ¬¡09:00 JSTå®Ÿè¡Œ |
| F-9 | å¤±æ•—æ™‚ã¯æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã¨ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ã€‚GitHub Actions ã®å®Ÿè¡Œãƒ­ã‚°ã§ç¢ºèªå¯èƒ½ |
| F-10 | LangGraph ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ« `workflow.yaml` ã‚’ä½œæˆã—ã€å„ãƒãƒ¼ãƒ‰ã®å†åˆ©ç”¨ã‚’å®¹æ˜“ã«ã™ã‚‹ |
| F-11 | LLM å‘¼ã³å‡ºã—ã¯ `llm_router.invoke(task="summary")` ã§ **Gemini â†’ Claude â†’ GPT-4o** ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ 3 æ®µéšã‚’å®Ÿè£… |
| F-12 | FAISS index ãƒ•ã‚¡ã‚¤ãƒ« `data/faiss/index.bin` ã‚’ Git LFS ã§ç®¡ç†ã—ã€Phase-2 ã§ Supabase ã¸ç§»è¡Œ <br/>â€» ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º (macOS/Windows) ã§ã¯ **FAISS ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªãã¦ã‚‚** `EmbeddingManager` ãŒ scikit-learn ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§å‹•ä½œã™ã‚‹ãŸã‚ã€ä¾å­˜ã‚¨ãƒ©ãƒ¼ã‚’å›é¿å¯èƒ½ |
| F-13 | Playwright Chromium ã‚’ GitHub Actions ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€OGP ã‚¸ãƒ§ãƒ–ã®å®Ÿè¡Œæ™‚é–“ã‚’ 30 ç§’ä»¥å†…ã«æŠ‘ãˆã‚‹ |
| F-14 | Prompt å®šç¾©ã¯ `prompts/*.yaml` ã§ç®¡ç†ã—ã€LangSmith run-id ã‚’ processing_logs ã«è¨˜éŒ² |
| F-15 | å½“æ—¥åˆ†ã®è¨˜äº‹ã‚’ Embedding+FAISS ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€ä»£è¡¨è¨˜äº‹ã‚’é¸æŠã€‚åŒä¸€ã‚¯ãƒ©ã‚¹ã‚¿ã®é–¢é€£è¨˜äº‹ï¼ˆRSS/YouTubeï¼‰ã‹ã‚‰æœ€å¤§3ä»¶ã‚’å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦æŠ½å‡ºã—ã€å®Ÿéš›ã®è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ãƒ»URL ã§ `>` ãƒ–ãƒ­ãƒƒã‚¯ã«å·®ã—è¾¼ã‚€ã€‚è¦ç´„ã¯ **3-4é …ç›®ã®ç®‡æ¡æ›¸ã** ã¨ã—ã€pytest ã§é …ç›®æ•°ãƒ»å¼•ç”¨æ•°ã‚’æ¤œè¨¼ |
| F-16 | **éå»è¨˜äº‹æ–‡è„ˆåæ˜ ã‚·ã‚¹ãƒ†ãƒ **: å„ãƒ‹ãƒ¥ãƒ¼ã‚¹å€™è£œã‚’éå»7æ—¥é–“ã®é…ä¿¡æ¸ˆã¿è¨˜äº‹ã¨Embeddingé¡ä¼¼æ¤œç´¢ã§ç…§åˆã€‚é¡ä¼¼è¨˜äº‹ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€LLMãŒã€ŒSKIPï¼ˆé‡è¤‡ï¼‰ã€ã€ŒUPDATEï¼ˆç¶šå ±ã¨ã—ã¦æ–‡è„ˆåæ˜ ï¼‰ã€ã€ŒKEEPï¼ˆç‹¬ç«‹è¨˜äº‹ï¼‰ã€ã‚’åˆ¤å®šã€‚UPDATEåˆ¤å®šæ™‚ã¯éå»ã®çµŒç·¯ã‚’è¸ã¾ãˆãŸè¦ç´„ã«è‡ªå‹•ä¿®æ­£ã—ã€é–¢é€£ã™ã‚‹éå»è¨˜äº‹ã¸ã®ãƒªãƒ³ã‚¯ã‚’ä»˜ä¸ã€‚ç¶šå ±è¨˜äº‹ã®è¦‹å‡ºã—ã«ã¯æœ«å°¾ã«ğŸ†™çµµæ–‡å­—ã‚’ä»˜ä¸ |
| F-17 | **æ–‡è„ˆç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: Supabase `contextual_articles` ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¨˜äº‹é–“ã®é–¢ä¿‚æ€§ï¼ˆç¶šå ±ã€é–¢é€£ãƒˆãƒ”ãƒƒã‚¯ã€ã‚·ãƒªãƒ¼ã‚ºï¼‰ã‚’è¨˜éŒ²ã€‚è¨˜äº‹ç”Ÿæˆæ™‚ã«é–¢é€£è¨˜äº‹ãƒã‚§ãƒ¼ãƒ³ã‚’è‡ªå‹•æ§‹ç¯‰ã—ã€ã€Œã€ç¶šå ±ã€‘ã€ã€Œã€é–¢é€£ã€‘ã€ã‚¿ã‚°ã¨éå»è¨˜äº‹ãƒªãƒ³ã‚¯ã‚’è‡ªå‹•ä»˜ä¸ |
| F-18 | `--target-date YYYY-MM-DD` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ä»»æ„ã®æ—¥ä»˜ã®ã¿ã‚’å¯¾è±¡ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ç”Ÿæˆã§ãã‚‹ |

---

## 6. Non-functional Requirements
| åŒºåˆ† | å†…å®¹ |
|------|------|
| ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ | 30 ä»¶å‡¦ç†ã§ 3 åˆ†ä»¥å†… (ä¸¦åˆ—åŒ–å®Ÿè£…å¾Œã€å¾“æ¥æ¯”40-50%çŸ­ç¸®) |
| å¯è¦³æ¸¬æ€§ | `logs/` ã«æ§‹é€ åŒ– JSON ãƒ­ã‚°ã€Supabase processing_logs ã«æ°¸ç¶šåŒ– |
| ä¿¡é ¼æ€§ | LLM å¤±æ•—æ™‚ã¯ RetryÃ—2 â†’ fallback_simple_summary |
| ã‚³ã‚¹ãƒˆ | æœˆ $30 ä»¥å†… (OpenAI+Supabase) |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ | API Key ã¯ GitHub Secrets ç®¡ç†ã€‚RLS ã§ anon role ã¯èª­ã¿å–ã‚Šã®ã¿ |

---

## 7. ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ (æ¦‚ç•¥)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub      â”‚ cron â”‚    main.py      â”‚
â”‚  Actions      â”‚â”€â”€â”€â”€â”€â–¶â”‚   (Python)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”œâ”€ fetch RSS   â”‚
                       â”‚  â”œâ”€ fetch YT   â”‚
                       â”‚  â”œâ”€ filter     â”‚
                       â”‚  â”œâ”€ LLM     â”‚
                       â”‚  â”œâ”€ dedup      â”‚
                       â”‚  â”œâ”€ render MD  â”‚
                       â”‚  â”œâ”€ write DB   â”‚
                       â”‚  â””â”€ call Quailyâ”‚
                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
          Supabase (processed_content / logs)        Quaily Platform
```

### 7.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆï¼ˆæ–‡è„ˆç¶™æ‰¿å¯¾å¿œï¼‰

**contextual_articles ãƒ†ãƒ¼ãƒ–ãƒ«**
```sql
CREATE TABLE contextual_articles (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  article_id VARCHAR NOT NULL,
  title TEXT NOT NULL,
  content_summary TEXT NOT NULL,
  embedding VECTOR(1536), -- OpenAI text-embedding-3-small
  published_date TIMESTAMP NOT NULL,
  source_url TEXT,
  topic_cluster VARCHAR,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE article_relationships (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  parent_article_id UUID REFERENCES contextual_articles(id),
  child_article_id UUID REFERENCES contextual_articles(id),
  relationship_type VARCHAR NOT NULL, -- 'sequel', 'related', 'update'
  similarity_score FLOAT,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### 7.2 æ–‡è„ˆåˆ¤å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ

**prompts/context_analysis.yaml**
```yaml
context_analysis_prompt: |
  ä¸ãˆã‚‰ã‚ŒãŸ"ä»Šå›ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹"ã¨"éå»é¡ä¼¼ãƒ‹ãƒ¥ãƒ¼ã‚¹"ã‚’æ¯”è¼ƒã—ã€ä»¥ä¸‹ã®çµæœã‚’è¿”ã™ã“ã¨ã€‚
  
  - éå»ã®ãƒˆãƒ”ãƒƒã‚¯ã¨å®Œå…¨ã«é‡è¤‡ãªã‚‰"SKIP"
  - ä¸€éƒ¨æ›´æ–°ãŒå¿…è¦ãªã‚‰"UPDATE" 
    - ä¾‹ï¼šéå»ã®é¡ä¼¼ãƒˆãƒ”ãƒƒã‚¯ã®ç¶šå ±ã€æ–°å±•é–‹ã€è¿½åŠ æƒ…å ±
    - ã“ã®å ´åˆã€éå»ã®æ–‡è„ˆã‚’è¸ã¾ãˆãŸä¿®æ­£è¦ç´„ã‚‚è¿”ã™ã“ã¨
  - å•é¡Œãªã‘ã‚Œã°"KEEP"
  
  # ä»Šå›ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹
  {current_news}
  
  # éå»é¡ä¼¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆé–¢é€£åº¦é †ï¼‰
  {past_related_news}
  
  # å‡ºåŠ›å½¢å¼
  {
    "decision": "SKIP|UPDATE|KEEP",
    "reasoning": "åˆ¤å®šç†ç”±",
    "contextual_summary": "éå»ã®æ–‡è„ˆã‚’åæ˜ ã—ãŸè¦ç´„ï¼ˆUPDATEã®å ´åˆã®ã¿ï¼‰",
    "references": ["é–¢é€£ã™ã‚‹éå»è¨˜äº‹ã®ID"]
  }
```

### 7.3 å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¾‹

```python
class ContextualSummarySystem:
    def __init__(self):
        self.embedding_model = "text-embedding-3-small"  # OpenAI
        self.faiss_index = faiss.IndexFlatIP(1536)  # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        self.past_articles_db = []  # éå»è¨˜äº‹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    
    def find_related_articles(self, current_article, top_k=4):
        """ç¾åœ¨ã®è¨˜äº‹ã«é–¢é€£ã™ã‚‹éå»è¨˜äº‹ã‚’æ¤œç´¢"""
        current_embedding = self.get_embedding(current_article['title'] + current_article['content'])
        distances, indices = self.faiss_index.search(current_embedding, top_k)
        return [self.past_articles_db[i] for i in indices[0]]
```

### 7.4 ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰

**å®šæ•°ç®¡ç†ã®é›†ç´„åŒ–**
```
src/constants/
â”œâ”€â”€ __init__.py              # å®šæ•°ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å®šç¾©
â”œâ”€â”€ mappings.py              # ä¼æ¥­ãƒ»è£½å“ãƒ»ã‚½ãƒ¼ã‚¹åãƒãƒƒãƒ”ãƒ³ã‚°çµ±ä¸€ç®¡ç†
â”œâ”€â”€ settings.py              # æ•°å€¤è¨­å®šã¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®šæ•°
â””â”€â”€ messages.py              # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ–‡è¨€
```

**å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£**
```
src/utils/
â”œâ”€â”€ text_processing.py       # æ—¥æœ¬èªå‡¦ç†å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ citation_generator.py    # å¼•ç”¨ç”Ÿæˆï¼ˆå®šæ•°å‚ç…§ã«æ›´æ–°ï¼‰
â”œâ”€â”€ newsletter_generator.py  # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ç”Ÿæˆï¼ˆå®šæ•°å‚ç…§ã«æ›´æ–°ï¼‰
â””â”€â”€ ... (ä»–ã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«)
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**
- **ä¸¦åˆ—LLMå‡¦ç†**: `check_duplicates_node_parallel()` ã§è¨˜äº‹å‡¦ç†ã‚’8ä¸¦åˆ—åŒ–
- **Citationä¸¦åˆ—ç”Ÿæˆ**: `enhance_articles_with_citations_parallel()` ã§å¼•ç”¨ã‚’ä¸¦åˆ—ç”Ÿæˆ
- **è¨­å®šé›†ç´„**: ä¸¦åˆ—æ•°ã€é–¾å€¤ã€åˆ¶é™å€¤ã‚’ã™ã¹ã¦`settings.py`ã§ä¸€å…ƒç®¡ç†

**å“è³ªå‘ä¸Šé …ç›®**
- **å®šæ•°çµ±ä¸€**: ä¼æ¥­åãƒ»è£½å“åãƒãƒƒãƒ”ãƒ³ã‚°ã®é‡è¤‡æ’é™¤
- **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é›†ç´„**: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–‡è¨€ã®ä¸€å…ƒç®¡ç†
- **ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†å…±é€šåŒ–**: æ—¥æœ¬èªæ­£è¦åŒ–å‡¦ç†ã®é–¢æ•°åŒ–
- **ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼æ’é™¤**: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ•°å€¤ã®å®šæ•°åŒ–

**æœŸå¾…åŠ¹æœ**
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: 3è¨˜äº‹145ç§’ â†’ 60-80ç§’ï¼ˆ40-50%çŸ­ç¸®ï¼‰
- **ä¿å®ˆæ€§**: 1ç®‡æ‰€ã®å®šæ•°å¤‰æ›´ã§ã™ã¹ã¦ã«åæ˜ 
- **ä¸€è²«æ€§**: ä¼æ¥­åãƒ»è£½å“åã®è¡¨è¨˜çµ±ä¸€
- **å¯èª­æ€§**: ã‚³ãƒ¼ãƒ‰ã®æ„å›³ãŒæ˜ç¢ºåŒ–

---

## 8. å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚ºå®šç¾©

### **Phase 1: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰**
**ç›®æ¨™**: åŸºæœ¬çš„ãªRSS/YouTubeåé›†ã¨LLMè¦ç´„æ©Ÿèƒ½ã®å®Ÿè£…

**å®Ÿè£…é …ç›®**:
- [x] ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã¨GitHubãƒªãƒã‚¸ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [x] RSS/YouTube ãƒ•ã‚£ãƒ¼ãƒ‰åé›†æ©Ÿèƒ½ (F-1)
- [x] AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (F-2)
- [x] LLMãƒ«ãƒ¼ã‚¿ãƒ¼å®Ÿè£…ï¼ˆGeminiâ†’Claudeâ†’GPT-4o-miniï¼‰ (F-3, F-11)
- [x] åŸºæœ¬çš„ãªé‡è¤‡é™¤å»ï¼ˆJaccard + SequenceMatcherï¼‰ (F-4)
- [x] Markdown ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ç”Ÿæˆï¼ˆJinja2ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰
- [x] ãƒ­ãƒ¼ã‚«ãƒ« drafts ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®å‡ºåŠ›æ©Ÿèƒ½ (F-7)
- [x] Supabase åŸºæœ¬ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆã¨æ¥ç¶š (F-6)
- [x] GitHub Actions åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ (F-8)

**æˆæœç‰©**: 
- æœ€å°é™ã®æ©Ÿèƒ½ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ç”ŸæˆãŒå¯èƒ½
- æ—¥æ¬¡å®Ÿè¡ŒãŒå®‰å®šå‹•ä½œ

**æŠ€è¡“æ¤œè¨¼**:
- LLM API ã®å®‰å®šæ€§ã¨ã‚³ã‚¹ãƒˆç¢ºèª
- Supabase æ¥ç¶šã¨ã‚¯ã‚¨ãƒªæ€§èƒ½

---

### **Phase 2: æ–‡è„ˆåæ˜ ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…**
**ç›®æ¨™**: éå»è¨˜äº‹ã¨ã®é–¢ä¿‚æ€§åˆ¤å®šã¨ç¶šå ±å‡¦ç†æ©Ÿèƒ½

**å®Ÿè£…é …ç›®**:
- [x] OpenAI Embedding API çµ±åˆ
- [x] FAISS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã¨ç®¡ç† (F-12, F-15)
- [x] éå»è¨˜äº‹é¡ä¼¼æ¤œç´¢æ©Ÿèƒ½ (F-16)
- [x] æ–‡è„ˆåˆ¤å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã¨å®Ÿè£… (F-16)
- [x] contextual_articles ãƒ†ãƒ¼ãƒ–ãƒ«å®Ÿè£… (F-17)
- [x] article_relationships ãƒ†ãƒ¼ãƒ–ãƒ«å®Ÿè£… (F-17)
- [x] ç¶šå ±è¨˜äº‹ã®ğŸ†™çµµæ–‡å­—ä»˜ä¸æ©Ÿèƒ½
- [x] é–¢é€£è¨˜äº‹ãƒªãƒ³ã‚¯è‡ªå‹•ç”Ÿæˆ

**æˆæœç‰©**:
- éå»è¨˜äº‹ã‚’è€ƒæ…®ã—ãŸæ–‡è„ˆåæ˜ è¦ç´„
- ç¶šå ±è¨˜äº‹ã®è‡ªå‹•åˆ¤å®šã¨é©åˆ‡ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

**æŠ€è¡“æ¤œè¨¼**:
- Embeddingæ¤œç´¢ã®ç²¾åº¦ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- æ–‡è„ˆåˆ¤å®šã®å“è³ªè©•ä¾¡

---

### **Phase 3: å“è³ªä¿è¨¼ãƒ»è‡ªå‹•åŒ–å¼·åŒ–**
**ç›®æ¨™**: æœ¬ç•ªé‹ç”¨ã«å‘ã‘ãŸå“è³ªå‘ä¸Šã¨è‡ªå‹•åŒ–

**å®Ÿè£…é …ç›®**:
- [x] ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ (F-15)
- [x] å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯è‡ªå‹•ç”Ÿæˆï¼ˆæœ€å¤§3ä»¶ï¼‰ (F-15)
- [x] Structured Output å®Ÿè£…ï¼ˆPydanticï¼‰
- [x] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  (F-14)
- [x] LangSmith ãƒˆãƒ¬ãƒ¼ã‚¹çµ±åˆ (F-14)
- [x] pytest ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆæ§‹ç¯‰
- [x] ã‚¹ã‚¿ã‚¤ãƒ«æ¤œè¨¼è‡ªå‹•åŒ–ï¼ˆæŒ‡ç¤ºèªãƒã‚§ãƒƒã‚¯ç­‰ï¼‰
- [x] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
- [x] ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ï¼ˆå®šæ•°ç®¡ç†ãƒ»ä¸¦åˆ—åŒ–ãƒ»å“è³ªå‘ä¸Šï¼‰

**æˆæœç‰©**:
- é«˜å“è³ªã§ä¸€è²«ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼å‡ºåŠ›
- åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
- é‹ç”¨ç›£è¦–æ©Ÿèƒ½
- ä¿å®ˆæ€§ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ä¸€è²«æ€§ãŒå‘ä¸Šã—ãŸã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹

**æŠ€è¡“æ¤œè¨¼**:
- ä¸¦åˆ—åŒ–ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼ˆ40-50%çŸ­ç¸®ç¢ºèªï¼‰
- ã‚¨ãƒ©ãƒ¼ç‡ã¨ãƒªã‚«ãƒãƒªãƒ¼æ©Ÿèƒ½ã®ç¢ºèª
- å®šæ•°ç®¡ç†ã¨ã‚³ãƒ¼ãƒ‰å“è³ªã®å‘ä¸Šç¢ºèª

---

### **Phase 4: Quailyçµ±åˆãƒ»é…ä¿¡è‡ªå‹•åŒ–**
**ç›®æ¨™**: å®Œå…¨è‡ªå‹•é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºç«‹

**å®Ÿè£…é …ç›®**:
- [x] Quaily CLI çµ±åˆã¨ãƒ†ã‚¹ãƒˆ
- [x] drafts ã‹ã‚‰ Quaily ã¸ã®è‡ªå‹•å…¥ç¨¿æ©Ÿèƒ½
- [x] é…ä¿¡å‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½
- [x] é…ä¿¡å±¥æ­´ç®¡ç†
- [x] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ãƒªã‚«ãƒãƒªæ©Ÿèƒ½
- [x] é…ä¿¡å¤±æ•—æ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
- [x] Slacké€šçŸ¥æ©Ÿèƒ½ï¼ˆé…ä¿¡æˆåŠŸãƒ»å¤±æ•—ã®é€šçŸ¥ï¼‰
- [x] é…ä¿¡æˆåŠŸç‡ç›£è¦–

**æˆæœç‰©**:
- å®Œå…¨è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼é…ä¿¡
- å®‰å®šã—ãŸæ—¥æ¬¡é‹ç”¨

**æŠ€è¡“æ¤œè¨¼**:
- Quaily API ã®å®‰å®šæ€§ç¢ºèª
- é…ä¿¡æˆåŠŸç‡95%ä»¥ä¸Šã®é”æˆ

---

### **Phase 5: æ‹¡å¼µæ©Ÿèƒ½ãƒ»æœ€é©åŒ–**
**ç›®æ¨™**: è¿½åŠ ä¾¡å€¤æ©Ÿèƒ½ã¨é•·æœŸé‹ç”¨æœ€é©åŒ–

**å®Ÿè£…é …ç›®**:
- [ ] OGPç”»åƒè‡ªå‹•ç”Ÿæˆï¼ˆPlaywright + HTML/CSSï¼‰
- [ ] Supabase pgvector ç§»è¡Œæ¤œè¨
- [ ] é…ä¿¡æ™‚é–“æœ€é©åŒ–
- [ ] A/Bãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
- [ ] èª­è€…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†æ©Ÿèƒ½
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–å¼·åŒ–
- [ ] ã‚³ã‚¹ãƒˆæœ€é©åŒ–
- [ ] ãƒ­ã‚°åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆSupabaseï¼‰

**æˆæœç‰©**:
- è¦–è¦šçš„ã«é­…åŠ›çš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼
- ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãªå“è³ªæ”¹å–„ã‚µã‚¤ã‚¯ãƒ«

**æŠ€è¡“æ¤œè¨¼**:
- é•·æœŸé‹ç”¨ã§ã®å®‰å®šæ€§ç¢ºèª
- ROI æœ€é©åŒ–

---

## 9. ãƒªã‚¹ã‚¯ & å¯¾ç­–
1. **LLM API å¤‰å‹•** â†’ fallback_simple_summary / ãƒ¢ãƒ‡ãƒ«åˆ‡æ›¿ã‚ªãƒ—ã‚·ãƒ§ãƒ³
2. **Supabase è‡ªå‹• Pause** â†’ heartbeat ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
3. **RSS ã‚½ãƒ¼ã‚¹åœæ­¢** â†’ content_sources ãƒ†ãƒ¼ãƒ–ãƒ«ã§å®¹æ˜“ã« ON/OFF
4. **Quaily API ä»•æ§˜å¤‰æ›´** â†’ quail-cli ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ pin ï¼†éšæ™‚ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ

---

## 10. æ‰¿èª
| å½¹å‰² | åå‰ | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |
|------|------|------------|
| ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã‚ªãƒ¼ãƒŠãƒ¼ | Lawrence | â˜ |
| ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒªãƒ¼ãƒ‰   | AI Assistant | â˜ |

---

## 11. å‚è€ƒã«ã—ãŸãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
ã“ã®è¨˜äº‹ã¯ [[11_zettelkasten/Literature/202504/AIãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’æ”¯ãˆã‚‹æŠ€è¡“.md]] ã®å®Ÿè£…çŸ¥è¦‹ã‚’è¸ã¾ãˆã¦è¨­è¨ˆã—ã¦ã„ã‚‹ã€‚

| æ¡ç”¨å…ƒã‚¢ã‚¤ãƒ‡ã‚¢ | æœ¬ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã§ã®é©ç”¨æ–¹æ³• |
|----------------|---------------------------|
| **LangGraph ãƒ™ãƒ¼ã‚¹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè£…** | Python è£½ `langgraph` ã§ã€Œå–å¾—â†’è¦ç´„â†’é‡è¤‡åˆ¤å®šâ†’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°â†’æŠ•ç¨¿ã€ã®ãƒãƒ¼ãƒ‰ã‚’å®šç¾©ã—ã€çŠ¶æ…‹é·ç§»ã‚’å›³ç¤ºå¯èƒ½ã«ã™ã‚‹ã€‚|
| **ãƒãƒ«ãƒ LLM ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (Geminiâ†’Claudeâ†’OpenAI)** | `llm_router.py` ã§ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’å…±é€šåŒ–ã—ã€è¦ç´„ãƒ»å°å…¥æ–‡ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã«å†åˆ©ç”¨ã€‚|
| **FAISS + Embedding ã«ã‚ˆã‚‹é‡è¤‡æ’é™¤** | Phase-2 ã§ pgvector å°å…¥ã¾ã§ã¯ãƒ­ãƒ¼ã‚«ãƒ« `faiss.IndexFlatIP` ã‚’åˆ©ç”¨ã€‚éå»7æ—¥åˆ†ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿æŒã—é¡ä¼¼åº¦>0.85 ã‚’é‡è¤‡åˆ¤å®šã€‚|
| **OGP ç”»åƒç”Ÿæˆ: LLM ãŒ HTML ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ›¸ã Playwright ã§ã‚¹ã‚¯ã‚·ãƒ§** | Phase-2 æ©Ÿèƒ½ã¨ã—ã¦ `ogp_generator.py` ã‚’è¿½åŠ ã€‚Gemini ã§ãƒ†ãƒ³ãƒ—ãƒ¬å¤‰æ•°ã‚’åŸ‹ã‚è¾¼ã¿ã€Chromium headless ã§ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã€‚|
| **Structured Output (JSON Schema) ã§ LLM è¿”å´ã‚’æ¤œè¨¼** | Pydantic ãƒ¢ãƒ‡ãƒ« `SummaryOutput` / `ContextAnalysisResult` ã§å‡ºåŠ›å½¢å¼ã‚’å³å¯†å®šç¾©ã€‚LangChain Structured Output ã‚’æ´»ç”¨ã—ã€ä¸æ­£ãªå‡ºåŠ›ã‚’äº‹å‰é˜²æ­¢ |

---

## 12. æŠ€è¡“å®Ÿè£…è©³ç´°ä»•æ§˜

### 12.1 Structured Outputå®Ÿè£…ï¼ˆPydanticï¼‰

**models/schemas.py**
```python
from pydantic import BaseModel, Field
from typing import List, Optional, Literal

class NewsArticle(BaseModel):
    title: str = Field(..., max_length=150)
    source_url: str
    published_date: str
    content_summary: str

class SummaryOutput(BaseModel):
    summary_points: List[str] = Field(..., min_items=3, max_items=4)
    confidence_score: float = Field(..., ge=0.0, le=1.0)
    source_reliability: Literal["high", "medium", "low"]
    
    class Config:
        json_schema_extra = {
            "example": {
                "summary_points": [
                    "OpenAIãŒGPT-5ã®é–‹ç™ºã‚’ç™ºè¡¨ã€2025å¹´å¾ŒåŠãƒªãƒªãƒ¼ã‚¹äºˆå®š",
                    "æ¨è«–èƒ½åŠ›ãŒå¤§å¹…å‘ä¸Šã€æ•°å­¦ãƒ»ç§‘å­¦åˆ†é‡ã§ã®ç²¾åº¦ãŒ50%æ”¹å–„",
                    "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½å¼·åŒ–ã€å‹•ç”»ç†è§£ãŒå¯èƒ½ã«"
                ],
                "confidence_score": 0.85,
                "source_reliability": "high"
            }
        }

class ContextAnalysisResult(BaseModel):
    decision: Literal["SKIP", "UPDATE", "KEEP"]
    reasoning: str = Field(..., max_length=500)
    contextual_summary: Optional[str] = Field(None, max_length=1000)
    references: List[str] = Field(default_factory=list)
    similarity_score: float = Field(..., ge=0.0, le=1.0)
```

### 12.2 LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè£…

**workflow/newsletter_workflow.py**
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List

class NewsletterState(TypedDict):
    raw_articles: List[dict]
    filtered_articles: List[dict]
    summarized_articles: List[dict]
    deduplicated_articles: List[dict]
    clustered_articles: List[dict]
    final_newsletter: str
    processing_logs: List[dict]

def create_newsletter_workflow():
    workflow = StateGraph(NewsletterState)
    
    # ãƒãƒ¼ãƒ‰å®šç¾©
    workflow.add_node("fetch_sources", fetch_rss_youtube)
    workflow.add_node("filter_ai_content", filter_ai_keywords)
    workflow.add_node("generate_summaries", generate_llm_summaries)
    workflow.add_node("check_duplicates", check_duplicate_content)
    workflow.add_node("cluster_topics", cluster_similar_topics)
    workflow.add_node("generate_newsletter", render_markdown_newsletter)
    
    # ã‚¨ãƒƒã‚¸å®šç¾©
    workflow.add_edge("fetch_sources", "filter_ai_content")
    workflow.add_edge("filter_ai_content", "generate_summaries")
    workflow.add_edge("generate_summaries", "check_duplicates")
    workflow.add_edge("check_duplicates", "cluster_topics")
    workflow.add_edge("cluster_topics", "generate_newsletter")
    workflow.add_edge("generate_newsletter", END)
    
    workflow.set_entry_point("fetch_sources")
    return workflow.compile()
```

### 12.3 é‡è¤‡åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯çµ±ä¸€å®Ÿè£…

**deduplication/duplicate_checker.py**
```python
import faiss
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from difflib import SequenceMatcher

class HybridDuplicateChecker:
    def __init__(self):
        self.embedding_model = "text-embedding-3-small"
        self.faiss_index = faiss.IndexFlatIP(1536)
        self.tfidf_vectorizer = TfidfVectorizer(max_features=1000)
        
    def check_duplicate(self, current_article: dict, past_articles: List[dict]) -> dict:
        """
        2æ®µéšé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼š
        1. é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆTF-IDF + Jaccardï¼‰
        2. ç²¾å¯†åˆ¤å®šï¼ˆEmbeddingé¡ä¼¼åº¦ï¼‰
        """
        # Stage 1: é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        potential_duplicates = self._fast_screening(current_article, past_articles)
        
        if not potential_duplicates:
            return {"is_duplicate": False, "method": "fast_screening"}
            
        # Stage 2: Embeddingç²¾å¯†åˆ¤å®š
        embedding_result = self._embedding_similarity_check(
            current_article, potential_duplicates
        )
        
        return embedding_result
    
    def _fast_screening(self, current: dict, past_articles: List[dict]) -> List[dict]:
        """Jaccardä¿‚æ•° + SequenceMatcher ã«ã‚ˆã‚‹é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        candidates = []
        current_text = f"{current['title']} {current['content']}"
        
        for past_article in past_articles:
            past_text = f"{past_article['title']} {past_article['content']}"
            
            # Jaccardä¿‚æ•°è¨ˆç®—
            jaccard_score = self._jaccard_similarity(current_text, past_text)
            
            # SequenceMatcherè¨ˆç®—
            sequence_ratio = SequenceMatcher(None, current_text, past_text).ratio()
            
            if jaccard_score > 0.4 or sequence_ratio > 0.6:  # ç·©ã‚ã®é–¾å€¤ã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                candidates.append({
                    **past_article,
                    "jaccard_score": jaccard_score,
                    "sequence_ratio": sequence_ratio
                })
        
        return candidates[:10]  # ä¸Šä½10ä»¶ã®ã¿Embeddingåˆ¤å®šã¸
    
    def _embedding_similarity_check(self, current: dict, candidates: List[dict]) -> dict:
        """Embeddingé¡ä¼¼åº¦ã«ã‚ˆã‚‹ç²¾å¯†é‡è¤‡åˆ¤å®š"""
        current_embedding = self._get_embedding(f"{current['title']} {current['content']}")
        
        max_similarity = 0.0
        most_similar_article = None
        
        for candidate in candidates:
            candidate_embedding = self._get_embedding(
                f"{candidate['title']} {candidate['content']}"
            )
            
            similarity = np.dot(current_embedding, candidate_embedding)
            
            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_article = candidate
        
        # é‡è¤‡åˆ¤å®šé–¾å€¤
        if max_similarity > 0.85:
            return {
                "is_duplicate": True,
                "method": "embedding_similarity",
                "similarity_score": max_similarity,
                "duplicate_article": most_similar_article
            }
        
        return {"is_duplicate": False, "method": "embedding_similarity"}
```

### 12.4 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥

**utils/error_handler.py**
```python
import asyncio
import logging
from typing import Callable, Any, Optional
from functools import wraps

class LLMRetryHandler:
    def __init__(self, max_retries: int = 3, backoff_factor: float = 2.0):
        self.max_retries = max_retries
        self.backoff_factor = backoff_factor
        self.logger = logging.getLogger(__name__)
    
    def with_fallback(self, primary_model: str, fallback_models: List[str]):
        """LLMãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ããƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
        def decorator(func: Callable) -> Callable:
            @wraps(func)
            async def wrapper(*args, **kwargs):
                models_to_try = [primary_model] + fallback_models
                
                for i, model in enumerate(models_to_try):
                    kwargs['model'] = model
                    
                    for attempt in range(self.max_retries):
                        try:
                            result = await func(*args, **kwargs)
                            
                            # çµæœæ¤œè¨¼
                            if self._validate_llm_output(result):
                                self.logger.info(f"Success with {model} on attempt {attempt + 1}")
                                return result
                            else:
                                raise ValueError(f"Invalid output from {model}")
                                
                        except Exception as e:
                            wait_time = self.backoff_factor ** attempt
                            self.logger.warning(
                                f"Attempt {attempt + 1} failed for {model}: {str(e)}"
                            )
                            
                            if attempt < self.max_retries - 1:
                                await asyncio.sleep(wait_time)
                            else:
                                # æœ€å¾Œã®ãƒ¢ãƒ‡ãƒ«ã®æœ€å¾Œã®è©¦è¡ŒãŒå¤±æ•—ã—ãŸå ´åˆ
                                if i == len(models_to_try) - 1:
                                    return self._fallback_simple_summary(*args, **kwargs)
                                break  # æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ã¸
                
                return self._fallback_simple_summary(*args, **kwargs)
            
            return wrapper
        return decorator
    
    def _validate_llm_output(self, output: Any) -> bool:
        """LLMå‡ºåŠ›ã®å¦¥å½“æ€§æ¤œè¨¼"""
        if not output:
            return False
            
        # Pydanticãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
        if hasattr(output, 'model_validate'):
            try:
                output.model_validate(output.model_dump())
                return True
            except Exception:
                return False
        
        # æ–‡å­—åˆ—ã®å ´åˆã®åŸºæœ¬æ¤œè¨¼
        if isinstance(output, str):
            forbidden_phrases = [
                "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“", "ã™ã¿ã¾ã›ã‚“", "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ",
                "I apologize", "I'm sorry", "I cannot"
            ]
            return not any(phrase in output for phrase in forbidden_phrases)
        
        return True
    
    def _fallback_simple_summary(self, *args, **kwargs) -> dict:
        """å…¨LLMãŒå¤±æ•—ã—ãŸå ´åˆã®ç°¡æ˜“è¦ç´„"""
        self.logger.error("All LLM attempts failed, using fallback summary")
        
        # å…ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ€åˆã®200æ–‡å­—ã‚’ä½¿ç”¨
        article = kwargs.get('article', {})
        title = article.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
        content = article.get('content', '')[:200] + "..."
        
        return {
            "summary_points": [
                f"ã€é€Ÿå ±ã€‘{title}",
                f"è©³ç´°: {content}",
                "â€»è‡ªå‹•è¦ç´„ãŒå¤±æ•—ã—ãŸãŸã‚ã€å…ƒè¨˜äº‹ã‚’ã”ç¢ºèªãã ã•ã„"
            ],
            "confidence_score": 0.1,
            "source_reliability": "low",
            "fallback_used": True
        }

# ä½¿ç”¨ä¾‹
retry_handler = LLMRetryHandler(max_retries=3)

@retry_handler.with_fallback(
    primary_model="gemini-2.5-pro",
    fallback_models=["claude-3.7-sonnet", "gpt-4o-mini"]
)
async def generate_summary(article: dict, model: str) -> SummaryOutput:
    # LLMå‘¼ã³å‡ºã—å®Ÿè£…
    pass
```

### 12.5 GitHub Actionså®Ÿè£…è©³ç´°

**.github/workflows/newsletter.yml**
```yaml
name: Daily Newsletter Generation

on:
  schedule:
    - cron: '0 0 * * *'  # 09:00 JST (00:00 UTC)
  workflow_dispatch:  # æ‰‹å‹•å®Ÿè¡Œå¯èƒ½

jobs:
  generate-newsletter:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - uses: actions/checkout@v4
      with:
        lfs: true  # FAISS indexãƒ•ã‚¡ã‚¤ãƒ«ç”¨
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Cache FAISS Index
      uses: actions/cache@v3
      with:
        path: data/faiss/
        key: faiss-index-${{ hashFiles('data/faiss/metadata.json') }}
        restore-keys: faiss-index-
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        playwright install chromium
    
    - name: Generate Newsletter
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
      run: |
        python main.py --max-items 30 --edition daily --output-dir drafts/
    
    - name: Upload Newsletter Draft
      uses: actions/upload-artifact@v3
      with:
        name: newsletter-draft
        path: drafts/
    
    - name: Notify on Failure
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        text: "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ç”ŸæˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
```

### 12.6 ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ & æ—¥æœ¬èªæœ€é©åŒ–

| å¤‰æ›´ç‚¹ | å®Ÿè£…ç®‡æ‰€ | åŠ¹æœ |
|---------|-----------|-------|
| å°å…¥æ–‡ã‚’å¿…ãš 3 æ–‡æ§‹æˆã§ç”Ÿæˆã—ã€æ–‡ã”ã¨ã«æ”¹è¡Œ | `newsletter_generator._generate_lead_text` | èª­ã¿ã‚„ã™ã„ãƒªãƒ¼ãƒ‰æ–‡ã€è¦ç‚¹ãŒæ˜ç¢º |
| ç›®æ¬¡ãƒ»è¦‹å‡ºã—ã‚’è‹±èªã‚¿ã‚¤ãƒˆãƒ«ã§ã¯ãªã **æ—¥æœ¬èªè¦ç´„ã‚¿ã‚¤ãƒˆãƒ«** ã«ç½®æ› | `daily_newsletter.jinja2` | ä¸€ç›®ã§å†…å®¹ã‚’æŠŠæ¡ã—ã‚„ã™ã„ |
| ç›®æ¬¡è¡Œãƒ»è¦‹å‡ºã—ç›´å¾Œã«ç©ºè¡Œã‚’æŒ¿å…¥ | `daily_newsletter.jinja2` | Markdown ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ã®æ”¹è¡Œæ¬ è½ã‚’é˜²æ­¢ |
| ã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚¯é™¤å» | `daily_newsletter.jinja2` | ãƒã‚¤ã‚ºå‰Šæ¸›ãƒ»å¯èª­æ€§å‘ä¸Š |
| ç®‡æ¡æ›¸ãä¿è¨¼ï¼ˆ3-4 è¡Œï¼‰ & ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ | `SummaryOutput` ã‚¹ã‚­ãƒ¼ãƒ | ä½“è£å´©ã‚Œé˜²æ­¢ |
| å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã«æ—¥æœ¬èª 1 è¡Œè¦ç´„ã‚’è¿½åŠ ã€é¡ä¼¼åº¦ 0.75 æœªæº€ã¯é™¤å¤– | `citation_generator` | æƒ…å ±é‡ã‚’æ‹…ä¿ã—ã¤ã¤ç„¡é–¢ä¿‚è¨˜äº‹ã‚’æ’é™¤ |

### 12.7 å“è³ªã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«å¼·åŒ– (Phase 3å®Œäº†)

| å±¤ | ç›®çš„ | å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ |
|----|------|--------------|
| å…¥åŠ›å“è³ª | ç„¡é–¢ä¿‚ã‚½ãƒ¼ã‚¹ãƒ»ãƒ€ãƒŸãƒ¼URLé®æ–­ | AIContentFilter ã‚’ Embedding ãƒ™ãƒ¼ã‚¹ã¸æ‹¡å¼µã€`quality_rank` ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆé©ç”¨ |
| LLM å‡ºåŠ› | JSON é€¸è„±ãƒ»bulletä¸è¶³ã‚’è‡ªå·±ä¿®æ­£ | `StructuredOutputParser.with_retry()` + `ContentValidator` ERROR ã§è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ |
| å‡ºåŠ›å‰ | Markdown ç”Ÿæˆç›´å‰ã«æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ | ä¸åˆæ ¼è¨˜äº‹ã‚’ SKIPã€ã‚¸ãƒ§ãƒ–ãƒ­ã‚°è¨˜éŒ² |

### 12.8 é‡è¦ãªå“è³ªæ”¹å–„ (2025-06-24 å®Œäº†)

| å•é¡Œ | åŸå›  | è§£æ±ºç­– | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |
|------|------|--------|----------|
| Bay Area Timesã®éé–¢é€£å¼•ç”¨ | å¹…åºƒãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ä¸è¶³ | AIã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3å€‹ä»¥ä¸Š+åœ°æ”¿å­¦é™¤å¤–å¼·åŒ– | âœ… å®Œäº† |
| TOCã‚¿ã‚¤ãƒˆãƒ«ä¸­é€”åˆ‡æ–­ | ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿é‡è¤‡é©ç”¨ | 80æ–‡å­—ãƒãƒ©ãƒ³ã‚¹+æ–‡å¢ƒç•Œæ¤œå‡º | âœ… å®Œäº† |
| å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯å“è³ªä¸å‡ä¸€ | æ—¥æœ¬èªè¦ç´„é•·åº¦åˆ¶ç´„ä¸è¶³ | 80-200æ–‡å­—å¼·åˆ¶+å†ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ | âœ… å®Œäº† |
| Embeddingãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ | æ–‡å­—åˆ—å½¢å¼ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸å‚™ | JSON+evalãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£… | âœ… å®Œäº† |

---

## 13. å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæŠ€è¡“ä»•æ§˜æº–æ‹ ï¼‰

### 13.1 æœ€çµ‚å‡ºåŠ›å½¢å¼ï¼ˆdrafts/2025-06-21_newsletter.mdï¼‰

```markdown
# 2025å¹´06æœˆ21æ—¥ AI NEWS TLDR

## ãƒªãƒ¼ãƒ‰æ–‡
### OpenAI o3é€²åŒ–ã¨Altmanæ°ã®æœªæ¥äºˆæ¸¬ï¼šæ€¥é€Ÿã«å¤‰åŒ–ã™ã‚‹AIæ¥­ç•Œã®æœ€æ–°å‹•å‘

OpenAIãŒé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«o3-proã‚’ChatGPT Pro/Teamãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨APIã§æä¾›é–‹å§‹ã—ã€åŒæ™‚ã«æ—¢å­˜o3ãƒ¢ãƒ‡ãƒ«ã®å¤§å¹…å€¤ä¸‹ã’ã¨åˆ©ç”¨æ å€å¢—ã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚

ä¸€æ–¹ã€Sam Altman CEOã¯ã€Œç©ã‚„ã‹ãªç‰¹ç•°ç‚¹ã€ã¨é¡Œã—ãŸãƒ–ãƒ­ã‚°ã§ã€AIãŒäººé–“ã‚ˆã‚ŠçŸ¥çš„ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹æœªæ¥ã‚’äºˆæ¸¬ã€‚ã¾ãŸå¤å¾ŒåŠã«äºˆå®šã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯ã€Œäºˆæƒ³å¤–ã®ç´ æ™´ã‚‰ã—ã„æˆæœã€ã®ãŸã‚å»¶æœŸã•ã‚Œã¦ã„ã¾ã™ã€‚

ä¼æ¥­ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™ºã‚‚åŠ é€Ÿã—ã¦ãŠã‚Šã€ãƒ¡ãƒ«ã‚«ãƒªã®ãƒ‡ãƒ¼ã‚¿åˆ†æAIã€ŒSocratesã€æ§‹ç¯‰ã‚„Algomaticã®ç‚ä¸Šå¯¾ç­–AIãªã©å…·ä½“çš„ãªæ´»ç”¨äº‹ä¾‹ãŒç¶šã€…ã¨ç™»å ´ã—ã¦ã„ã¾ã™ã€‚

ãã‚Œã§ã¯å„ãƒˆãƒ”ãƒƒã‚¯ã®è©³ç´°ã‚’è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚

## ç›®æ¬¡
1. OpenAI GPT-5ç™ºè¡¨ã€æ¨è«–èƒ½åŠ›ãŒå¤§å¹…å‘ä¸Š
2. Google Quantum AIã€é‡å­å„ªä½æ€§ã‚’AIå­¦ç¿’ã«å¿œç”¨
3. Metaã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã®æ–°æˆ¦ç•¥ç™ºè¡¨

---

## 1. OpenAI GPT-5ç™ºè¡¨ã€æ¨è«–èƒ½åŠ›ãŒå¤§å¹…å‘ä¸Š ğŸ†™

- OpenAIãŒGPT-5ã®é–‹ç™ºå®Œäº†ã‚’ç™ºè¡¨ã€2025å¹´å¾ŒåŠã®ä¸€èˆ¬å…¬é–‹ã‚’äºˆå®šã™ã‚‹ã¨ç™ºè¡¨ã—ã¾ã—ãŸ
- æ•°å­¦ãƒ»ç§‘å­¦åˆ†é‡ã§ã®æ¨è«–ç²¾åº¦ãŒå‰ä¸–ä»£æ¯”50%å‘ä¸Šã€è¤‡é›‘ãªå•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å¤§å¹…å¼·åŒ–ã—ã¦ã„ã‚‹ã‚ˆã†ã§ã™
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½ãŒé€²åŒ–ã—ã€å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç†è§£ãƒ»ç”ŸæˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™
- ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘APIã¯2025å¹´Q3ã‹ã‚‰æ®µéšçš„æä¾›é–‹å§‹ã™ã‚‹ã¨ã•ã‚Œã€å‰µä½œãƒ•ãƒ­ãƒ¼ã¸å°å…¥ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹è¦‹è¾¼ã¿ã§ã™

> **TechCrunch** (https://techcrunch.com/openai-gpt5-announcement): OpenAI announces GPT-5 with breakthrough reasoning capabilities
> ã€ç¿»è¨³ã€‘GPT-5ã¯å‰ä¸–ä»£æ¯”50ï¼…ç²¾åº¦å‘ä¸Šã€è¤‡é›‘æ¨è«–ã‚’å®Ÿç¾ã€‚ä¼æ¥­APIã¯2025å¹´Q3é–‹å§‹äºˆå®š

> **The Verge** (https://theverge.com/gpt5-multimodal-features): GPT-5's multimodal features could revolutionize content creation
> ã€ç¿»è¨³ã€‘å¼·åŒ–ã•ã‚ŒãŸGPT-5ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½ã§å‹•ç”»ç†è§£ãƒ»ç”ŸæˆãŒå¯èƒ½ã€å‰µä½œãƒ•ãƒ­ãƒ¼ã‚’é©æ–°

> **AI News Channel** (https://youtube.com/watch?v=xyz123): GPT-5 Demo: Solving Complex Mathematical Proofs
> ã€ç¿»è¨³ã€‘ãƒ‡ãƒ¢ã§GPT-5ãŒé«˜åº¦ãªæ•°å­¦è¨¼æ˜ã‚’è‡ªå‹•ç”Ÿæˆã—æ­£å½“æ€§ã‚’æ¤œè¨¼ã€ç ”ç©¶å¿œç”¨ã®å¯èƒ½æ€§ç¤ºã™

**é–¢é€£è¨˜äº‹**: [2025å¹´06æœˆ15æ—¥: OpenAI GPT-4.5ã®æ€§èƒ½è©•ä¾¡çµæœ](../2025-06-15_newsletter.md#gpt-45-performance)

---

## 2. Google Quantum AIã€é‡å­å„ªä½æ€§ã‚’AIå­¦ç¿’ã«å¿œç”¨

- Google Quantum AIãƒãƒ¼ãƒ ãŒé‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’æ´»ç”¨ã—ãŸAIå­¦ç¿’æ‰‹æ³•ã‚’ç™ºè¡¨ã—ã¾ã—ãŸ
- å¾“æ¥ã®GPUã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨æ¯”è¼ƒã—ã¦å­¦ç¿’æ™‚é–“ã‚’90%çŸ­ç¸®ã™ã‚‹ã“ã¨ã«æˆåŠŸã—ã¦ã„ã¾ã™
- ç‰¹ã«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦é¡•è‘—ãªåŠ¹æœã‚’ç¢ºèªã•ã‚ŒãŸã¨ã®ã“ã¨
- 2026å¹´ã«ã¯å•†ç”¨é‡å­AIå­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹ã®æä¾›ã‚’è¨ˆç”»ã§ã™

> **Nature AI** (https://nature.com/quantum-ai-breakthrough): Quantum advantage in machine learning training achieved
> ã€ç¿»è¨³ã€‘é‡å­ãƒ—ãƒ­ã‚»ãƒƒã‚µã§AIå­¦ç¿’æ™‚é–“ã‚’90ï¼…çŸ­ç¸®ã€ç²¾åº¦ç¶­æŒã—ãŸé‡å­å„ªä½æ€§ã‚’å®Ÿè¨¼ã—ãŸ

> **Google AI Blog** (https://ai.googleblog.com/quantum-ml-training): Scaling AI training with quantum processors
> ã€ç¿»è¨³ã€‘é‡å­AIå­¦ç¿’åŸºç›¤ã‚’å…¬é–‹ã€å˜ä½ã‚³ã‚¹ãƒˆåŠæ¸›ã¨å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¹ã‚±ãƒ¼ãƒ«æ¤œè¨¼ã‚’å ±å‘Šã—ã¾ã™

---

## 3. Metaã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã®æ–°æˆ¦ç•¥ç™ºè¡¨

- MetaãŒLlama 3.5ã‚·ãƒªãƒ¼ã‚ºã®é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’å…¬é–‹ã€å®Œå…¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã‚’æ¨é€²
- å•†ç”¨åˆ©ç”¨åˆ¶é™ã‚’æ’¤å»ƒã—ã€ä¼æ¥­ã§ã®è‡ªç”±ãªåˆ©ç”¨ãƒ»æ”¹å¤‰ã‚’è¨±å¯
- ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ä¸»å°ã®é–‹ç™ºä½“åˆ¶ã‚’å¼·åŒ–ã€æœˆæ¬¡ã§ã®ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚’å®Ÿæ–½äºˆå®š
- OpenAIãƒ»Anthropicã®å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã«å¯¾æŠ—ã™ã‚‹ç„¡æ–™ä»£æ›¿æ¡ˆã¨ã—ã¦ä½ç½®ã¥ã‘

> **Meta AI Research** (https://ai.meta.com/llama-3-5-announcement): Llama 3.5: Democratizing Advanced AI
> ã€ç¿»è¨³ã€‘Llama 3.5ã¯å•†ç”¨åˆ¶é™æ’¤å»ƒã—å®Œå…¨OSSåŒ–ã€æ¯æœˆã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§å”èª¿é–‹ç™ºã‚’ä¿ƒé€²

---

### 13.2 å‡¦ç†ãƒ­ã‚°å‡ºåŠ›ä¾‹ï¼ˆlogs/newsletter_2025-06-21.jsonï¼‰

```json
{
  "processing_id": "newsletter_20250621_090000",
  "timestamp": "2025-06-21T00:00:00Z",
  "status": "SUCCESS",
  "execution_time_seconds": 247,
  "stages": {
    "fetch_sources": {
      "rss_articles": 23,
      "youtube_videos": 7,
      "total_fetched": 30,
      "duration_seconds": 45
    },
    "filter_ai_content": {
      "input_count": 30,
      "filtered_count": 18,
      "ai_relevance_threshold": 0.7,
      "duration_seconds": 12
    },
    "generate_summaries": {
      "input_count": 18,
      "successful_summaries": 15,
      "failed_summaries": 3,
      "llm_usage": {
        "gemini_success": 12,
        "claude_fallback": 2,
        "gpt4o_fallback": 1,
        "total_tokens": 45670
      },
      "duration_seconds": 156
    },
    "check_duplicates": {
      "input_count": 15,
      "duplicates_found": 3,
      "updates_applied": 1,
      "final_count": 12,
      "embedding_comparisons": 180,
      "duration_seconds": 23
    },
    "cluster_topics": {
      "input_count": 12,
      "clusters_formed": 3,
      "representative_articles": 3,
      "citations_added": 9,
      "duration_seconds": 8
    },
    "generate_newsletter": {
      "template": "daily_newsletter.jinja2",
      "output_file": "drafts/2025-06-21_newsletter.md",
      "word_count": 1247,
      "duration_seconds": 3
    }
  },
  "quality_metrics": {
    "summary_instruction_words": 0,
    "citation_count": 9,
    "bullet_points_per_topic": [4, 4, 3],
    "readability_score": 8.2
  },
  "costs": {
    "openai_embedding": 0.12,
    "gemini_api": 0.34,
    "claude_api": 0.08,
    "total_usd": 0.54
  },
  "langsmith_run_id": "run_abc123def456"
}